[English](../README.md) Â· [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](README.ar.md) Â· [EspaÃ±ol](README.es.md) Â· [FranÃ§ais](README.fr.md) Â· [æ—¥æœ¬èª](README.ja.md) Â· [í•œêµ­ì–´](README.ko.md) Â· [Tiáº¿ng Viá»‡t](README.vi.md) Â· [ä¸­æ–‡ (ç®€ä½“)](README.zh-Hans.md) Â· [ä¸­æ–‡ï¼ˆç¹é«”ï¼‰](README.zh-Hant.md) Â· [Deutsch](README.de.md) Â· [Ğ ÑƒÑÑĞºĞ¸Ğ¹](README.ru.md)


# lazylanguagelearner


[![License: Apache-2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)
![Python](https://img.shields.io/badge/Python-3.10%2B-3776AB?logo=python&logoColor=white)
![Status](https://img.shields.io/badge/Status-Script--Driven-orange)
![Web](https://img.shields.io/badge/Web-Tornado-5C2D91?logo=tornado)
![AI](https://img.shields.io/badge/OpenAI-API-10A37F?logo=openai&logoColor=white)

Lerne Sprachen auf eine faule Art.

## ğŸŒ Ãœberblick

LazyLanguageLearner ist ein Python-basierter Sprachlern-Workflow, der Folgendes kombiniert:

- PDF-Beschaffung fÃ¼r Rosetta-Stone-Kursinhaltsdokumente.
- PDF-Parsing und Satzextraktion in CSV-DatensÃ¤tze.
- OpenAI-gestÃ¼tzte mehrsprachige Satzkonvertierung mit Phonetik-Paaren und lokalem Festplatten-Cache.
- Eine schlanke Tornado-Web-App, die mehrsprachigen Text mit Ruby-Phonetikannotationen rendert.

Das aktuelle Repository ist skriptgetrieben (noch nicht als Pip-Modul paketiert), mit Datendateien und Notebooks direkt im Repo.

## âœ¨ Funktionen

- LÃ¤dt Sprachkurs-PDFs aus Links herunter, die in `rs_html.py` eingebettet sind (`download_course_text.py`).
- Extrahiert Abschnitts-/Satzdaten aus PDFs in strukturierte CSV (`pdf_to_csv.py`, `language_extraction.py`).
- Cached OpenAI-Prompt-/Response-Daten in `cache/*.json`, um wiederholte API-Nutzung zu reduzieren (`openai_request.py`).
- Parst KI-Antworten in JSON mit Retry-Logik und benutzerdefinierten JSON-Parsing-Fehlern.
- Stellt mehrsprachige SatzblÃ¶cke aus `translations.json` Ã¼ber Tornado bereit (`app.py` + `templates/index.html`).
- EnthÃ¤lt japanische Phonetik-Normalisierung (`katakana` zu `hiragana`) vor dem Rendering.

## ğŸ—‚ï¸ Projektstruktur

```text
.
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ app.py
â”œâ”€â”€ download_course_text.py
â”œâ”€â”€ rs_html.py
â”œâ”€â”€ pdf_extraction.py
â”œâ”€â”€ pdf_to_csv.py
â”œâ”€â”€ language_extraction.py
â”œâ”€â”€ openai_request.py
â”œâ”€â”€ multilingual_sentence.py
â”œâ”€â”€ translations.json
â”œâ”€â”€ japanese_language_data.csv
â”œâ”€â”€ japanese_language_data copy.csv
â”œâ”€â”€ processed_words.csv
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ cache/
â”‚   â””â”€â”€ *.json
â”œâ”€â”€ i18n/
â”‚   â””â”€â”€ (derzeit leer)
â””â”€â”€ *.ipynb
```

## âœ… Voraussetzungen

Annahmen (da derzeit kein Lockfile oder Dependency-Manifest eingecheckt ist):

- Python 3.10+ (funktioniert wahrscheinlich auch auf nahegelegenen Versionen; exakte getestete Matrix ist nicht deklariert).
- `pip` und `venv`.
- OpenAI-API-Key fÃ¼r modellgestÃ¼tzte Skripte.

Aus Imports abgeleitete Python-AbhÃ¤ngigkeiten:

| Package | Verwendet von |
|---|---|
| `tornado` | Webserver in `app.py` |
| `openai` | API-Aufrufe in `openai_request.py` |
| `PyPDF2` | PDF-Parsing in Extraktionsskripten |
| `requests` | PDF-Downloads in `download_course_text.py` |
| `beautifulsoup4` | HTML-Parsing im Downloader |

## ğŸ› ï¸ Installation

```bash
# from repository root
python3 -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
pip install tornado openai PyPDF2 requests beautifulsoup4
```

## ğŸš€ Verwendung

### 1) Quell-PDFs herunterladen

```bash
python download_course_text.py
```

Dies erstellt `downloaded_pdfs/` und speichert dort Sprach-/Unit-PDFs.

### 2) Japanische PDF-Inhalte nach CSV extrahieren

```bash
python pdf_to_csv.py
```

Standardausgabe des aktuellen Skripts: `japanese_language_data.csv`.

### 3) (Optional) Abschnitts-/Seiten-/Satztext interaktiv zuschneiden

```bash
python language_extraction.py
```

Das Skript enthÃ¤lt bearbeitbare Beispielvariablen (`level`, `section`, `sentence_num`) und gibt extrahierten Text aus.

### 4) Mehrsprachiges JSON mit OpenAI-Flow generieren

```bash
python multilingual_sentence.py
```

Hinweise zum aktuellen Verhalten:

- Es wird nur die erste CSV-Zeile verarbeitet (`break` in der Schleife).
- Das Skript referenziert derzeit eine undefinierte Variable (`japanese_text`) bei der Prompt-Erstellung und braucht daher vor zuverlÃ¤ssiger Nutzung einen kleinen Fix.

### 5) Die Web-App starten

```bash
python app.py
```

- Tornado lauscht auf Port `7788`.
- Im Browser Ã¶ffnen: `http://localhost:7788/`.
- Hinweis: Das Start-Log gibt derzeit `http://localhost:8888` aus, obwohl gebunden auf `7788`.

## âš™ï¸ Konfiguration

Umgebungsvariablen:

| Variable | Erforderlich | Zweck | Aktueller Standard |
|---|---|---|---|
| `OPENAI_API_KEY` | Ja | Erforderlich fÃ¼r `OpenAI()`-Client-Initialisierung | N/A |
| `OPENAI_MODEL` | Nein | Optionales Override fÃ¼r das Chat-Modell | `gpt-4-0125-preview` |

Laufzeitdateien/-verzeichnisse:

- `downloaded_pdfs/`: vom Downloader erstellt, von Extraktionsskripten verwendet.
- `cache/`: Request-/Response-Cache fÃ¼r OpenAI-Aufrufe.
- `translations.json`: Datenquelle fÃ¼r Tornado-UI-Rendering.

## ğŸ§¾ Datenformat-Beispiele

### CSV (`japanese_language_data.csv`)

Von `pdf_to_csv.py` verwendeter Header:

```csv
Level,Unit,Section,Sentence No.,Content
```

### JSON (`translations.json`)

Die Web-UI erwartet SprachschlÃ¼ssel mit `pairs`-EintrÃ¤gen, die `part` und `phonetic` enthalten:

```json
{
  "ja": {
    "full": "...",
    "pairs": [
      { "part": "æ—¥", "phonetic": "ã²" }
    ]
  },
  "en": { "full": "...", "pairs": [] },
  "ar": { "full": "...", "pairs": [] },
  "zh": { "full": "...", "pairs": [] },
  "yue": { "full": "...", "pairs": [] }
}
```

## ğŸ§ª Entwicklungshinweise

- Dieses Repo hat derzeit kein `requirements.txt`, `pyproject.toml` oder CI-Workflow.
- Skripte sind fÃ¼r die direkte AusfÃ¼hrung vom Repository-Root ausgelegt.
- Bestehende Notebooks (`*.ipynb`) wirken explorativ/prototyping-orientiert.
- GroÃŸe CSV-Artefakte sind direkt in Git versioniert.
- `i18n/` existiert und ist bereit fÃ¼r Ã¼bersetzte README-Varianten.

## ğŸ©º Fehlerbehebung

- `ModuleNotFoundError`: aus Imports abgeleitete AbhÃ¤ngigkeiten in der aktiven virtuellen Umgebung installieren.
- `OPENAI`-Auth-Fehler: sicherstellen, dass `OPENAI_API_KEY` in der Shell exportiert ist.
- `FileNotFoundError: downloaded_pdfs`: zuerst `python download_course_text.py` ausfÃ¼hren.
- `multilingual_sentence.py`-Fehler bei `japanese_text`: `japanese_text` in der Prompt-Konstruktion durch `content` ersetzen.
- Verwirrung um App-Port: `http://localhost:7788/` verwenden, sofern `app.listen(...)` nicht geÃ¤ndert wird.

## ğŸ›£ï¸ Roadmap

MÃ¶gliche nÃ¤chste Schritte fÃ¼r das Projekt:

- Dependency-Manifest hinzufÃ¼gen (`requirements.txt` oder `pyproject.toml`).
- Prompt-Variable in `multilingual_sentence.py` korrigieren und den Ein-Zeilen-`break` fÃ¼r Batch-Verarbeitung entfernen.
- Tornado-Startup-Print-URL mit gebundenem Port angleichen.
- Tests fÃ¼r PDF-Extraktions-Regex-Verhalten und JSON-Parsing-/Retry-Logik hinzufÃ¼gen.
- CLI-Argumente fÃ¼r Sprache/Level/Pfade hinzufÃ¼gen, um In-File-Bearbeitungen zu reduzieren.
- `i18n/` mit Ã¼bersetzten README-Dateien fÃ¼llen.

## ğŸ¤ Beitragen

BeitrÃ¤ge sind willkommen.

1. Repository forken.
2. Feature-Branch erstellen.
3. Fokussierte Ã„nderungen mit klaren Commit-Messages vornehmen.
4. Pull Request Ã¶ffnen, der beschreibt, was geÃ¤ndert wurde und warum.

Wenn du die Extraktionslogik Ã¤nderst, fÃ¼ge Beispiel-Input/Output-Snippets hinzu, damit das Review einfacher wird.

## ğŸ™ Danksagungen

- Rosetta-Stone-Kursinhaltslinks sind in `rs_html.py` eingebettet und werden als Quellreferenzen fÃ¼r PDF-Downloads verwendet.
- Die OpenAI API wird fÃ¼r mehrsprachige Generierung und Phonetik-Strukturierung genutzt.

## ğŸ“„ Lizenz

Dieses Projekt ist unter der Apache License 2.0 lizenziert. Siehe [LICENSE](LICENSE).
